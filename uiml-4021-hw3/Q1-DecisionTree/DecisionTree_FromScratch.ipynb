{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requied Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature_index, threshold, left, right, info_gain, value):\n",
    "        \"\"\"\n",
    "        Constructor for the Node class.\n",
    "\n",
    "        Parameters:\n",
    "        - feature_index (int): Index of the feature used for splitting at this node.\n",
    "        - threshold (float): Threshold value for splitting at this node.\n",
    "        - left (Node): Reference to the left child node.\n",
    "        - right (Node): Reference to the right child node.\n",
    "        - info_gain (float): Information gain from the split at this node.\n",
    "        - value (varied): The class label if this is a leaf node.\n",
    "        \"\"\"\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.info_gain = info_gain\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split, max_depth):\n",
    "       ''' \n",
    "        Constructor for the DecisionTreeClassifier class.\n",
    "        \n",
    "        Parameters:\n",
    "        min_samples_split (int): The minimum number of samples required to split a node.\n",
    "        max_depth (int): The maximum depth of the tree.\n",
    "        '''\n",
    "       self.min_samples_split = min_samples_split\n",
    "       self.max_depth = max_depth\n",
    "        \n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        ''' \n",
    "        Recursively builds the decision tree from the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (array): The data used to build the tree.\n",
    "        curr_depth (int): The current depth of the tree.\n",
    "        \n",
    "        Returns:\n",
    "        dict: The root node of the built tree.\n",
    "        '''\n",
    "        \n",
    "        # 1: Check stopping conditions\n",
    "        if len(dataset) < self.min_samples_split or curr_depth == self.max_depth:\n",
    "            # Create a leaf node and calculate the leaf value\n",
    "            leaf_value = self.calculate_leaf_value(dataset[:, -1])\n",
    "            return {'leaf': True, 'value': leaf_value}\n",
    "        \n",
    "        # 2: Find the best split\n",
    "        best_split = self.get_best_split(dataset, len(dataset), len(dataset[0]) - 1)\n",
    "        \n",
    "        # 3: Check if information gain is positive\n",
    "        if best_split['information_gain'] <= 0:\n",
    "            # Create a leaf node and calculate the leaf value\n",
    "            leaf_value = self.calculate_leaf_value(dataset[:, -1])\n",
    "            return {'leaf': True, 'value': leaf_value}\n",
    "        \n",
    "        # 4: Recur on the left child\n",
    "        left_child = self.build_tree(best_split['left_child'], curr_depth + 1)\n",
    "        \n",
    "        # 5: Recur on the right child\n",
    "        right_child = self.build_tree(best_split['right_child'], curr_depth + 1)\n",
    "        \n",
    "        # 6: Create a decision node\n",
    "        decision_node = {\n",
    "            'leaf': False,\n",
    "            'feature_index': best_split['feature_index'],\n",
    "            'threshold': best_split['threshold'],\n",
    "            'left_child': left_child,\n",
    "            'right_child': right_child\n",
    "        }\n",
    "        \n",
    "        # 7: Return the decision node\n",
    "        return decision_node\n",
    "        \n",
    "\n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        '''\n",
    "        Finds the best split for the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        dataset (array): The dataset to split.\n",
    "        num_samples (int): Number of samples in the dataset.\n",
    "        num_features (int): Number of features in the dataset.\n",
    "        \n",
    "        Returns:\n",
    "        dict: Information about the best split.    \n",
    "        '''\n",
    "\n",
    "        # 1: Define dictionary to store the best split \n",
    "        best_split = {}\n",
    "\n",
    "        # 2: loop over all the features\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = np.unique(dataset[:, feature_index])\n",
    "\n",
    "        # 3: loop over all the feature values present in the data\n",
    "            for threshold in feature_values:\n",
    "\n",
    "        # 4: get current split\n",
    "                left_child, right_child = self.split(dataset, feature_index, threshold)\n",
    "\n",
    "        # 5: check if childs are not null\n",
    "                if len(left_child) > 0 and len(right_child) > 0:\n",
    "\n",
    "        # 6: compute information gain\n",
    "                    mode = \"entropy\"\n",
    "                    information_gain = self.information_gain(dataset, left_child, right_child, mode)\n",
    "\n",
    "        # 7: update the best split if needed\n",
    "                    if \"information_gain\" not in best_split or information_gain > best_split[\"information_gain\"]:\n",
    "                        best_split = {\n",
    "                            \"feature_index\": feature_index,\n",
    "                            \"threshold\": threshold,\n",
    "                            \"left_child\": left_child,\n",
    "                            \"right_child\": right_child,\n",
    "                            \"information_gain\": information_gain,\n",
    "                        }\n",
    "\n",
    "        # 8: return best split\n",
    "        return best_split\n",
    "        \n",
    "\n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        \"\"\"\n",
    "        Splits the dataset based on the given feature index and threshold.\n",
    "\n",
    "        Parameters:\n",
    "        - dataset (array): The dataset to split.\n",
    "        - feature_index (int): The index of the feature used for splitting.\n",
    "        - threshold (float): The threshold value for splitting.\n",
    "\n",
    "        Returns:\n",
    "        - tuple: Two subsets of the dataset split by the threshold.\n",
    "        \"\"\"\n",
    "        left_subset = dataset[dataset[:, feature_index] <= threshold]\n",
    "        right_subset = dataset[dataset[:, feature_index] > threshold]\n",
    "        return left_subset, right_subset     \n",
    "\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        \"\"\"\n",
    "        Computes the information gain of a split.\n",
    "\n",
    "        Parameters:\n",
    "        - parent (array): The parent dataset before the split.\n",
    "        - l_child (array): The left child dataset after the split.\n",
    "        - r_child (array): The right child dataset after the split.\n",
    "        - mode (str): The criterion for information gain ('gini' or 'entropy').\n",
    "\n",
    "        Returns:\n",
    "        - float: The information gain of the split.\n",
    "        \"\"\"\n",
    "        if mode == \"gini\":\n",
    "            parent_impurity = self.gini_index(parent)\n",
    "            l_child_impurity = self.gini_index(l_child)\n",
    "            r_child_impurity = self.gini_index(r_child)\n",
    "        else:\n",
    "            parent_impurity = self.entropy(parent)\n",
    "            l_child_impurity = self.entropy(l_child)\n",
    "            r_child_impurity = self.entropy(r_child)\n",
    "\n",
    "        parent_size = len(parent)\n",
    "        l_child_size = len(l_child)\n",
    "        r_child_size = len(r_child)\n",
    "        total_child_size = l_child_size + r_child_size\n",
    "\n",
    "        information_gain = parent_impurity - (\n",
    "            (l_child_size / total_child_size) * l_child_impurity\n",
    "            + (r_child_size / total_child_size) * r_child_impurity\n",
    "        )\n",
    "\n",
    "        return information_gain\n",
    "    \n",
    "\n",
    "    def entropy(self, y):\n",
    "        \"\"\"\n",
    "        Computes the entropy of a dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - y (array): The labels of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - float: The entropy of the dataset.\n",
    "        \"\"\"\n",
    "        class_counts = np.unique(y, return_counts=True)[1]\n",
    "        class_probabilities = class_counts / len(y)\n",
    "        entropy = -np.sum(class_probabilities * np.log2(class_probabilities))\n",
    "        return entropy\n",
    "    \n",
    "\n",
    "    def gini_index(self, y):\n",
    "        \"\"\"\n",
    "        Computes the Gini index of a dataset.\n",
    "\n",
    "        Parameters:\n",
    "        - y (array): The labels of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - float: The Gini index of the dataset.\n",
    "        \"\"\"\n",
    "        class_counts = np.unique(y, return_counts=True)[1]\n",
    "        class_probabilities = class_counts / len(y)\n",
    "        gini_index = 1 - np.sum(class_probabilities ** 2)\n",
    "        return gini_index\n",
    "\n",
    "\n",
    "    def calculate_leaf_value(self, Y):\n",
    "        \"\"\"\n",
    "        Determines the value of a leaf node (most common class label).\n",
    "\n",
    "        Parameters:\n",
    "        - Y (array): The labels of the data in the leaf node.\n",
    "\n",
    "        Returns:\n",
    "        - varied: The most common class label in the leaf node.\n",
    "        \"\"\"\n",
    "        class_counts = np.unique(Y, return_counts=True)\n",
    "        most_common_label = class_counts[0][np.argmax(class_counts[1])]\n",
    "        return most_common_label\n",
    "    \n",
    "\n",
    "    def print_tree(self, tree, indent=\"   \"):\n",
    "        ''' \n",
    "        Prints the tree in a readable format.\n",
    "        \n",
    "        Parameters:\n",
    "        tree (Node, optional): The current node to print. If None, print from the root.\n",
    "        indent (str): The indentation string to format the tree structure.\n",
    "        '''\n",
    "        if tree is None:\n",
    "            return\n",
    "\n",
    "        if isinstance(tree, dict):\n",
    "            if tree['leaf']:\n",
    "                print(indent + \"Leaf Node: \", tree['value'])\n",
    "            else:\n",
    "                print(indent + \"Feature\", tree['feature_index'], \"<=\", tree['threshold'], \"?\")\n",
    "\n",
    "                print(indent + \"--> True:\")\n",
    "                self.print_tree(tree['left_child'], indent + \"  \")\n",
    "\n",
    "                print(indent + \"--> False:\")\n",
    "                self.print_tree(tree['right_child'], indent + \"  \")\n",
    "    \n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        ''' \n",
    "        Trains the decision tree classifier.\n",
    "        \n",
    "        Parameters:\n",
    "        X (array): The features of the training data.\n",
    "        Y (array): The labels of the training data.\n",
    "        '''\n",
    "        dataset = np.column_stack((X, Y))\n",
    "        self.tree = self.build_tree(dataset)\n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts the class labels for the given data.\n",
    "\n",
    "        Parameters:\n",
    "        - X (array-like): The input data.\n",
    "\n",
    "        Returns:\n",
    "        - array: The predicted class labels.\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "\n",
    "        for sample in X:\n",
    "            node = self.tree\n",
    "\n",
    "            while not node['leaf']:\n",
    "                if sample[node['feature_index']] <= node['threshold']:\n",
    "                    node = node['left_child']\n",
    "                else:\n",
    "                    node = node['right_child']\n",
    "\n",
    "            predictions.append(node['value'])\n",
    "\n",
    "        return np.array(predictions)\n",
    "    \n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        ''' \n",
    "        Predicts a class label for a single data point.\n",
    "        \n",
    "        Parameters:\n",
    "        x (array): The features of the single data point.\n",
    "        tree (Node): The current node in the tree during the recursive prediction.\n",
    "        \n",
    "        Returns:\n",
    "        varied: The predicted class label.\n",
    "        '''\n",
    "        if tree['leaf']:\n",
    "            return tree['value']\n",
    "        \n",
    "        if x[tree['feature_index']] <= tree['threshold']:\n",
    "            return self.make_prediction(x, tree['left_child'])\n",
    "        else:\n",
    "            return self.make_prediction(x, tree['right_child'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('Dataset/train.csv')\n",
    "test_dataset = pd.read_csv('Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Id columns but keep y_test column Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_id = test_dataset['Id']\n",
    "\n",
    "# Drop the 'Id' column\n",
    "train_dataset = train_dataset.drop('Id', axis=1)\n",
    "test_dataset = test_dataset.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_dict = {\n",
    "    \"Iris-setosa\": 0,\n",
    "    \"Iris-versicolor\": 1,\n",
    "    \"Iris-virginica\": 2\n",
    "}\n",
    "\n",
    "train_dataset[\"Species\"] = train_dataset[\"Species\"].map(conversion_dict)\n",
    "test_dataset[\"Species\"] = test_dataset[\"Species\"].map(conversion_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Xs and Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'Species'\n",
    "\n",
    "X_train = train_dataset.drop(target_column, axis=1)\n",
    "y_train = train_dataset[target_column]\n",
    "\n",
    "X_test = test_dataset.drop(target_column, axis=1)\n",
    "y_test = test_dataset[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "0            5.4           3.0            4.5           1.5\n",
       "1            7.7           2.8            6.7           2.0\n",
       "2            5.2           3.4            1.4           0.2\n",
       "3            4.8           3.4            1.9           0.2\n",
       "4            6.6           3.0            4.4           1.4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 0, 0, 1, 2, 1, 1, 1, 2, 2, 0, 0, 0, 2, 0, 1, 0, 1, 2, 0, 1, 2, 0, 0, 0, 1, 2, 2, 1, 0, 1, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 2, 2, 2, 0, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 2, 0, 0, 2, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2, 1, 1, 2, 0, 0, 2, 1, 0, 2, 2, 0, 0, 1, 2, 1, 2, 0, 1, 0, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 0, 2, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Score From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        if true_label == pred_label:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Instance of DecisionTreeClassifier Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(4, 10)\n",
    "\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "predictions = tree.predict(X_test.values)\n",
    "accuracy = acc(y_test, predictions)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
